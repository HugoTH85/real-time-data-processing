# TP (not√©) : Plateforme de Streaming de Donn√©es en Temps R√©el avec Apache Kafka 

## Introduction

Le ***TP*** vise √† concevoir et mettre en ≈ìuvre une plateforme de streaming de donn√©es en temps r√©el √† l'aide d'***Apache Kafka***. La plateforme permettra la collecte, le traitement, le stockage et l'analyse de flux de donn√©es provenant de diverses sources, avec un accent sur la scalabilit√©, la r√©silience et les performances.

## Objectifs

- D√©ployer un ***cluster Kafka*** pour la gestion des flux de donn√©es.
- D√©velopper des producteurs de donn√©es pour simuler diff√©rentes sources de donn√©es.
- Impl√©menter des consommateurs pour traiter les donn√©es en temps r√©el.
- Int√©grer des outils pour le stockage, l'analyse et la visualisation des donn√©es.

## Architecture

### Composants du TP

### 1. Cluster Kafka

***Installation et Configuration :*** Installer ***Apache Kafka*** sur un ensemble de ***machines virtuelles*** ou ***conteneurs Docker***. Configurer le ***cluster Kafka*** avec ***plusieurs brokers*** pour garantir la redondance et la scalabilit√©.

***Gestion des Topics :*** Cr√©er des ***topics Kafka*** pour repr√©senter les diff√©rentes sources de donn√©es √† surveiller. Configurer les partitions et les r√©plicas pour chaque topic en fonction des besoins de scalabilit√© et de tol√©rance aux pannes.

***S√©curit√© :*** Configurer la s√©curit√© dans ***Kafka*** en utilisant ***SSL/TLS*** pour le chiffrement des communications et ***SASL*** pour l'authentification des clients.

### 2. Producteurs de Donn√©es

***Simulation de Sources de Donn√©es :*** D√©velopper des producteurs de donn√©es pour simuler diff√©rents types de flux de donn√©es :

- Un producteur pour simuler des journaux d'acc√®s web avec des informations sur les requ√™tes ***HTTP***, ***les adresses IP***, les temps de r√©ponse, etc.
- Un producteur pour simuler des donn√©es de capteurs ***IoT*** avec des mesures de temp√©rature, d'humidit√©, etc.
- Un producteur pour simuler des transactions financi√®res avec des informations sur les montants, les comptes concern√©s, etc.

***Envoi de Donn√©es √† Kafka :*** Configurer les producteurs pour envoyer les donn√©es g√©n√©r√©es aux ***topics Kafka*** correspondants. Utiliser la biblioth√®que ***Kafka Producer API*** pour garantir la fiabilit√© et la haute performance de l'envoi des donn√©es.

### 3. Consommateurs de Donn√©es

***Traitement en Temps R√©el :*** Impl√©menter des consommateurs de donn√©es pour effectuer des op√©rations de traitement en temps r√©el :

- Utiliser ***Kafka Streams*** pour effectuer des transformations, des agr√©gations et des fen√™trages sur les flux de donn√©es.

- Appliquer des filtres et des op√©rations de jointure pour enrichir les donn√©es avec des informations suppl√©mentaires.

- Int√©gration avec des Bases de Donn√©es : Int√©grer des bases de donn√©es ***NoSQL*** comme ***Apache Cassandra*** ou ***MongoDB*** pour stocker les donn√©es trait√©es :

  - Configurer ***les connecteurs Kafka*** pour synchroniser les donn√©es entre ***Kafka*** et les bases de donn√©es de stockage.

### 4. Analyse et Visualisation

***Analyse en Temps R√©el :*** Utiliser des outils d'analyse de donn√©es comme ***Apache Spark Streaming*** ou ***Apache Flink*** pour effectuer des analyses en temps r√©el sur les flux de donn√©es :

- Calculer des statistiques en temps r√©el telles que les moyennes, les maxima, les minima, etc.
- D√©tecter des mod√®les et des anomalies dans les flux de donn√©es.

***Tableaux de Bord Interactifs :*** Cr√©er des tableaux de bord interactifs avec des outils de visualisation comme ***Grafana*** ou ***Kibana*** :

- Afficher des graphiques en temps r√©el des m√©triques surveill√©es.
- Configurer des alertes pour notifier les utilisateurs en cas de conditions anormales ou critiques.

### D√©ploiement et Documentation

***Configuration et D√©ploiement :*** Fournir des scripts de configuration et de d√©ploiement pour faciliter le d√©ploiement de la plateforme sur diff√©rents environnements (local, cloud, etc.). Automatiser autant que possible les t√¢ches de configuration et de d√©ploiement √† l'aide d'outils d'infrastructure-as-code comme ***Ansible*** ou ***Terraform***.

***Documentation :*** R√©diger une documentation d√©taill√©e sur l'architecture de la plateforme, les composants utilis√©s et les flux de donn√©es. Inclure des guides d'installation, des tutoriels et des exemples de code pour aider les utilisateurs √† comprendre et √† utiliser la plateforme.

## Quelques API pour la collecte de donn√©es

### 1. API REST pour les Donn√©es de Capteurs IoT

***API IoT Weather:*** Fournit des donn√©es m√©t√©orologiques en temps r√©el, telles que la temp√©rature, l'humidit√©, la pression atmosph√©rique, etc.

- Site Web : https://www.weatherapi.com/

- Exemple d'endpoint : https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London

***API OpenAQ:*** Fournit des donn√©es sur la qualit√© de l'air provenant de stations de surveillance dans le monde entier.

- Site Web : https://openaq.org

- Exemple d'endpoint : https://api.openaq.org/v1/latest?city=Paris&parameter=pm25

### 2. API REST pour les Donn√©es de Trafic Routier

***API TomTom Traffic:*** Fournit des informations sur le trafic routier en temps r√©el, y compris les temps de trajet, les incidents, les embouteillages, etc.

- Site Web : https://developer.tomtom.com/traffic-api/traffic-api-documentation

- Exemple d'endpoint : https://api.tomtom.com/traffic/services/4/flowSegmentData/absolute/10/json?key=YOUR_API_KEY&point=48.77538,9.165247

***API Google Maps Traffic:*** Fournit des donn√©es sur le trafic routier en temps r√©el √† partir de ***Google Maps***.

- Site Web : https://developers.google.com/maps/documentation/traffic-data

- Exemple d'endpoint : https://maps.googleapis.com/maps/api/distancematrix/json?origins=Chicago,IL&destinations=Los+Angeles,CA&departure_time=now&traffic_model=best_guess&key=YOUR_API_KEY

### 3. API REST pour les Donn√©es de R√©seaux Sociaux

***Twitter API:*** Permet d'acc√©der aux tweets en temps r√©el ainsi qu'√† diverses informations sur les utilisateurs, les tendances, etc.

- Site Web : https://developer.twitter.com/en/docs/twitter-api

- Exemple d'endpoint : https://api.twitter.com/2/tweets/sample/stream

***Facebook Graph API:*** Permet d'acc√©der aux publications, aux commentaires, aux likes, etc., sur ***Facebook***.

- Site Web : https://developers.facebook.com/docs/graph-api

- Exemple d'endpoint : https://graph.facebook.com/{user-id}/posts?access_token=YOUR_ACCESS_TOKEN

### 4. API REST pour les Donn√©es de Finance

***Alpha Vantage API:*** Fournit des donn√©es sur les march√©s financiers, y compris les prix des actions, les volumes de n√©gociation, etc.

- Site Web : https://www.alphavantage.co/documentation/

- Exemple d'endpoint : https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey=YOUR_API_KEY

***Yahoo Finance API:*** Permet d'acc√©der √† diverses informations financi√®res, telles que les cours des actions, les indices boursiers, etc.

- Site Web : https://finance.yahoo.com/

- Exemple d'endpoint : https://query1.finance.yahoo.com/v8/finance/chart/GOOG?period1=0&period2=9999999999&interval=1d

## Exemple d'aplication

[Cliquez ici SVP](./METEO_KAFKA_STREAMLIT/)

## Conclusion

Ce ***TP*** vous permettra de d√©velopper une solide compr√©hension des concepts de streaming de donn√©es en temps r√©el et de leur mise en ≈ìuvre pratique √† l'aide d'***Apache Kafka***. Ils acquerront √©galement des comp√©tences pr√©cieuses en mati√®re de configuration, de d√©veloppement et de d√©ploiement de solutions de streaming de donn√©es dans des environnements r√©els.

***Good Luck*** üôÇ